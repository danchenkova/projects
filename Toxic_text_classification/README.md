# Классификация комментариев пользователей

Интернет-магазин «Викишоп» запускает новый сервис, где пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. Клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

В проекте требуется построить модель классификации комментариев на позитивные и негативные со значением метрики качества *F1* не меньше 0.75. Нам предоставлен набор данных с разметкой о токсичности правок (файл toxic_comments.csv). 

## Цель проекта

Построить наилучшую модель для классификации комментариев на токсичные и нетоксичные, основываясь на размеченных данных.

## Задачи проекта

1. Подготовить данные для анализа, обработать признаки, разделить на обучающую и тестовую выборки.
2. Исследовать базовые модели и рассмотреть, как меняются показатели оценки в зависимости от примененной модели. Подобрать гиперпараметры.
3. Выбрать наилучшую модель, по возможности доработать ее, учитывая дисбаланс классов. Проверить модели на тестовой выборке.

В предоставленном датасете имеется ярко выраженный дисбаланс классов. Примерно 90% текста правок не является токсичным.
Для разделения комментариев на позитивные и негативные применено 4 модели: логистическая регрессия, дерево решений, случайный лес и стохастический градиентный спуск. Одна из них (логистическая регрессия) обучалась как на основе оценок TF-IDF, так и на основе эмбеддингов. 

В сочетании с оценкой важности слов TF-IDF лучший итог выдала взвешенная логистическая регрессия (f1-score = 0.753 на валидационной выборке и 0.760 на тестовой). Модель немного завышает recall относительно precision. Это значит, что у нас будет много положительных ответов (в т.ч. и ложно), и модель признает нормальные комментарии токсичными чаще, чем нужно.
Логистическая регрессия в комбинации с BERT дала еще более высокие значения f1 (0.855 на валидационной выборке и 0.889 на тестовой). Здесь precision выше recall, а значит, модель будет более склонна признавать комментарии нетоксичными.

Используемые библиотеки: torch, transformers, pandas, matplotlib, scikit-learn, re, nltk, spacy.
